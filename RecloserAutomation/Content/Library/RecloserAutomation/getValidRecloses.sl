namespace: RecloserAutomation
operation:
  name: getValidRecloses
  inputs:
    - rundate:
        required: false
  python_action:
    use_jython: false
    script: "def execute(rundate):\r\n    global requests, xmltodict, date, datetime,timedelta,pd,os,xlsxwriter,xlrd,logging, root, yesterday\r\n    import requests\r\n    import xmltodict\r\n    from datetime import date, datetime, timedelta\r\n    import pandas as pd \r\n    import os\r\n    import xlsxwriter\r\n    import xlrd\r\n    import logging\r\n\r\n    root = \"C:/Users/svcrpabot/OneDrive - SA Power Networks/Recloser Patrol Automation/\"\r\n    \r\n    if rundate != \"\":\r\n        yesterday = datetime.strptime(rundate, '%d/%m/%Y').date() - timedelta(1)\r\n    else:\r\n        yesterday = datetime.today().date() - timedelta(1)\r\n    \r\n    # --- DEFINE GLOBALS ---\r\n    global recloseData, df_feederToWeatherStationMapping, df_bushFireRiskFeeders, df_bushFireRiskSubstations, df_substationToSSDMapping, df_stationToLocationCode\r\n    \r\n    # --- READ DATA ---\r\n    # Reclose Data\r\n    recloseData = pd.read_csv(f\"{root}ADMS Daily Incident Reports/Recloser Incidents {yesterday}.csv\")\r\n    # Weather Station to Feeder\r\n    df_feederToWeatherStationMapping = pd.read_excel(f\"{root}Automation Input Files/WeatherStationstoFeeders.xlsx\")\r\n    # Bush Fire Risk Feeders\r\n    df_bushFireRiskFeeders = pd.read_excel(f\"{root}Automation Input Files/BushFireRiskAreas.xlsx\")\r\n    # Bush Fire Risk Substation\r\n    df_bushFireRiskSubstations = pd.read_excel(f\"{root}Automation Input Files/BushFireRiskAreas_Substation.xls\")\r\n    # To get the SSD from the substation\r\n    df_substationToSSDMapping = pd.read_excel(f\"{root}Automation Input Files/SubstationToSSD.xlsx\")\r\n    # Weather station location codes\r\n    df_stationToLocationCode = pd.read_excel(f\"{root}Automation Input Files/ADMS_Weather_Regions_20220823.xlsx\")\r\n    # Daily phase data\r\n    df_phaseData = pd.read_csv(f\"{root}ADMS Daily Phase Data/Incident Phase Data {yesterday}.csv\")\r\n    # Signal to Phase map\r\n    df_signalToPhaseMapping = pd.read_excel(f\"{root}Automation Input Files/Signals List and Phases.xlsx\")\r\n    # Get feeder location data\r\n    df_feederLocation = pd.read_excel(f\"{root}Automation Input Files/Feeder Location.xlsx\")\r\n\r\n    # --- Clean Data ---\r\n    # Split SSD and Name in Substation bush fire data\r\n    df_bushFireRiskSubstations[[\"SSD\", \"Substation Name\"]] = df_bushFireRiskSubstations['Substation Name'].str.split(' ', 1, expand=True)\r\n    # Standardise Bush fire risk acronyms so final sheet doesn't have 2 acronyms for same meaning.\r\n    df_bushFireRiskSubstations[\"ABC indicator text\"] = df_bushFireRiskSubstations[\"ABC indicator text\"].str.replace(\"BFRA\", \"MBFRA\")\r\n    df_bushFireRiskSubstations[\"ABC indicator text\"] = df_bushFireRiskSubstations[\"ABC indicator text\"].str.replace(\"HBRA\", \"HBFRA\")\r\n    df_bushFireRiskSubstations[\"ABC indicator text\"] = df_bushFireRiskSubstations[\"ABC indicator text\"].str.replace(\"NBFR\", \"NBFRA\")\r\n    # Parse phase dates\r\n    # df_phaseData['Timestamp'] = pd.to_datetime(df_phaseData['Timestamp'], format='%m/%d/%Y %I:%M:%S %p')\r\n    \r\n    \r\n    # Run getting valid recloses\r\n    validRecloses = get_validRecloses(recloseData)\r\n    \r\n    if not validRecloses.empty:\r\n      validRecloses = get_averageRainfall(validRecloses)\r\n      validRecloses = get_weatherType(validRecloses)\r\n    else:\r\n      validRecloses[\"Average Rainfall\"] = \"\"\r\n      validRecloses[\"Weather Type\"] = \"\"\r\n      \r\n    \r\n\r\n    # Get event times for each incident\r\n    validRecloses = get_phaseData(recloseData, validRecloses, df_phaseData, df_signalToPhaseMapping)\r\n    # validRecloses = join_phaseData(validRecloses, df_phaseData, df_signalToPhaseMapping)\r\n    validRecloses = join_feederLocation(validRecloses, df_feederLocation)\r\n\r\n\r\n    # Save to csv\r\n    validRecloses.to_csv(f\"{root}Valid Reclose Output/validRecloses_{yesterday}.csv\", index=False)\r\n\r\ndef get_phaseData(recloseData, validRecloses, df_phaseData, df_signalToPhaseMapping):\r\n\r\n  validRecloses['Description'] = ''\r\n  reclose_NotNA = recloseData[recloseData[\"DATE_TIME_OPERATED\"].notna()].copy()\r\n\r\n  # Mapping dict\r\n  signalToPhaseMap = dict(zip(df_signalToPhaseMapping[\"Description\"], df_signalToPhaseMapping[\"Phase / Zone\"].astype(str)))\r\n\r\n  # Time conversion\r\n  reclose_NotNA = reclose_NotNA[reclose_NotNA[\"DATE_TIME_OPERATED\"] != \"001-01-01 10:30:00\"]\r\n  reclose_NotNA['DATE_TIME_OPERATED'] = pd.to_datetime(reclose_NotNA['DATE_TIME_OPERATED'], format='%Y-%m-%d %H:%M:%S')\r\n  df_phaseData['Timestamp'] = pd.to_datetime(df_phaseData['Timestamp'], format='%m/%d/%Y %I:%M:%S %p')\r\n\r\n  incidentsAndTimes = reclose_NotNA.groupby([\"Textbox35\", \"DEVICE_NAME\"]).agg({\"DATE_TIME_OPERATED\": list})\r\n  incidentsAndTimes = incidentsAndTimes.reset_index()\r\n\r\n  df_phaseData = df_phaseData.sort_values(\"Timestamp\", ascending=False)\r\n\r\n  for idx, recloseInc in validRecloses.iterrows():\r\n    times = sorted(incidentsAndTimes[incidentsAndTimes[\"Textbox35\"] == recloseInc[\"Incident ID\"]][\"DATE_TIME_OPERATED\"].values[0])\r\n    startTime = times[0] + pd.Timedelta(seconds=-20)\r\n    endTime = times[-1] + pd.Timedelta(seconds=20)\r\n    timeMask = (startTime<df_phaseData[\"Timestamp\"]) & (df_phaseData[\"Timestamp\"]<endTime)\r\n    deviceMask = df_phaseData[\"DeviceName\"] == recloseInc[\"Protection Device\"]\r\n    # descriptions = \", \".join(list(set(sorted(list(df_phaseData[timeMask & deviceMask][\"Description\"])))))\r\n    description_list = list(set(sorted(list(df_phaseData[timeMask & deviceMask][\"Description\"]))))\r\n    phase_list = [signalToPhaseMap.get(string, string) for string in description_list]\r\n    phase_list = [i for i in phase_list if i != 'nan']\r\n    if len(phase_list) == 0:\r\n      phase_list = [\"No Phase Data\"]\r\n    validRecloses.loc[ validRecloses[\"Incident ID\"] == recloseInc[\"Incident ID\"], 'Description'] = \", \".join(description_list)\r\n    validRecloses.loc[ validRecloses[\"Incident ID\"] == recloseInc[\"Incident ID\"], 'Phase / Zone'] = \", \".join(phase_list)\r\n    \r\n  return validRecloses\r\n\r\n\r\ndef join_feederLocation(validRecloses, df_feederLocation):\r\n  import re\r\n  validRecloses = pd.merge(validRecloses, df_feederLocation[['Feeder ID','Region']], left_on = validRecloses[\"Feeder ID\"].str.lower(), right_on = df_feederLocation['Feeder ID'].str.lower(), how='left')\r\n  validRecloses = validRecloses.drop([\"key_0\", \"Feeder ID_y\"], axis=1)\r\n  validRecloses = validRecloses.rename(columns={\"Feeder ID_x\": \"Feeder ID\", \"Region\": \"Feeder location\"})\r\n\r\n  # nonCountryRegions = [\"Southern Suburbs\", 'Eastern Suburbs', \"Western Suburbs\", \"Northern Suburbs\"]\r\n  # validRecloses[~validRecloses[\"Region\"].isin(nonCountryRegions)] = \"Country\" \r\n\r\n  return validRecloses\r\n\r\n\r\ndef join_phaseData(validRecloses, df_phaseData, df_signalToPhaseMapping):\r\n\r\n  df_phaseData['Timestamp'] = pd.to_datetime(df_phaseData['Timestamp'], format='%m/%d/%Y %I:%M:%S %p')\r\n  df_phaseData = df_phaseData.sort_values(\"Timestamp\", ascending=False)\r\n  df_phaseData = get_timeAdjustedPhase(df_phaseData, WINDOW=1)\r\n\r\n  for seconds in range(-20, 21):\r\n    # Create a copy so that df_phaseData isn't affected\r\n    df_phaseData_temp = df_phaseData.copy()\r\n    # Add seconds to introduce tolerance\r\n    df_phaseData_temp[\"Timestamp\"] = df_phaseData[\"Timestamp\"] + pd.Timedelta(seconds=seconds)\r\n    # Merge phase data to reclose data\r\n    validRecloses = pd.merge(validRecloses, df_phaseData_temp[['Description', 'Timestamp', 'DeviceName']],  how='left', left_on=['Outage Start Time','Protection Device'], right_on = ['Timestamp','DeviceName'])\r\n\r\n  # The merge process in the for loop creates many description x and y columns. We take all off these and backfill into one description column\r\n  validRecloses[\"Description\"] = validRecloses.filter(like='Description').ffill(axis=1).iloc[:,-1].astype(str).replace(\"nan\", \"No Description\")\r\n  validRecloses = validRecloses.drop([\"Description_x\", \"Description_y\", \"Timestamp\", \"Timestamp_x\", \"Timestamp_y\", \"DeviceName\", \"DeviceName_x\", \"DeviceName_y\"], axis=1) \r\n\r\n  # We merge the phase mapping to get description to phase/zone\r\n  validRecloses = pd.merge(validRecloses, df_signalToPhaseMapping[['Description', \"Phase / Zone\"]], how='left', on='Description')\r\n  validRecloses['Phase / Zone'] = validRecloses['Phase / Zone'].astype(str).replace(\"nan\", \"No Phase Data\")\r\n  \r\n  # The merges will have created extra rows for when there are multiple phases/trip signals for one reclose event.\r\n  # We can bring these rows together using groupby, and bring the phase data into one cell per reclose\r\n  validRecloses = validRecloses.groupby(list(validRecloses.drop(['Phase / Zone', \"Description\"], axis=1).columns), as_index = False, dropna=False).agg({'Phase / Zone': list, 'Description': list})\r\n  validRecloses['Description'] = validRecloses['Description'].apply(set).apply(sorted).apply(\", \".join)\r\n  validRecloses['Phase / Zone'] = validRecloses['Phase / Zone'].apply(set).apply(sorted).apply(list)\r\n\r\n  # Remove no phase data in the case other phase data is available. This gets mixed when we have more than 1 trip signal, where\r\n  # one is nan (e.g. No Phase Data) but the rest are valid. This way, when there is no valid signals, No Phase Data will show.\r\n  for idx, value in validRecloses['Phase / Zone'].iteritems():\r\n    if len(value) > 1 and \"No Phase Data\" in value:\r\n      validRecloses['Phase / Zone'][idx] = [i for i in value if i != \"No Phase Data\"]\r\n\r\n  validRecloses['Phase / Zone'] = validRecloses['Phase / Zone'].apply(\", \".join)\r\n\r\n  return validRecloses\r\n\r\ndef get_timeAdjustedPhase(df_phaseData, WINDOW=1):\r\n  # This corrects any phase signals within a window of time to be the same time.\r\n  # We do this because our algorithm relies on related signals coming through at the same time, \r\n  # to the second\r\n\r\n  # Iterate from last row as data is sorted from latest to earliest\r\n  # (This can be refectored, need to change bfill to ffill though)\r\n  for idx in range(WINDOW, len(df_phaseData)):\r\n    idx = idx*-1\r\n    posIdx = len(df_phaseData)+idx\r\n\r\n    row = df_phaseData.copy().iloc[idx]\r\n    for WINDOW_IDX in range(1, WINDOW+1):\r\n      if (row[\"Timestamp\"] + pd.Timedelta(seconds=WINDOW_IDX)) == df_phaseData.iloc[posIdx-1][\"Timestamp\"]:\r\n        df_phaseData.at[posIdx-WINDOW_IDX, \"Timestamp\"] = row[\"Timestamp\"]\r\n\r\n  return df_phaseData\r\n\r\ndef inflection_point_operation(lst):\r\n    c = None\r\n    for i, num in enumerate(lst[:-1]):\r\n        if num > lst[i+1]:\r\n            c = num\r\n            break\r\n    if c == None:\r\n        c = lst[-1]\r\n        b = 0\r\n    else:\r\n        b = lst[-1]\r\n    a = lst[0]\r\n    return c - a + b\r\n    \r\ndef create_total_rainfall_column(df,col_names):\r\n    # concatenating all the columns in to a single Series\r\n    series = pd.concat([df[col] for col in col_names], axis=1)\r\n    series = series.apply(lambda x: x.tolist(), axis=1)\r\n    df['Total Rainfall Within 4h Window (mm)'] = series.apply(inflection_point_operation)\r\n    return df\r\n\r\n# Get average rainfall\r\ndef get_averageRainfall(validRecloses):\r\n  weatherColumns = ['Rainfall-2h (mm)', \r\n          'Rainfall-1h (mm)',\r\n          'Rainfall+0h (mm)',\r\n          'Rainfall+1h (mm)',\r\n          'Rainfall+2h (mm)',\r\n          'Average Wind Speed (kph)']\r\n  for weatherColumn in weatherColumns: \r\n    validRecloses[weatherColumn] = validRecloses[weatherColumn].str.replace('na', '-1')\r\n\r\n\r\n  validRecloses = validRecloses.astype({'Rainfall-2h (mm)': 'float', \r\n\t\t\t\t\t\t\t\t\t'Rainfall-1h (mm)': 'float', \r\n\t\t\t\t\t\t\t\t\t'Rainfall+0h (mm)': 'float',\r\n\t\t\t\t\t\t\t\t\t'Rainfall+1h (mm)': 'float',\r\n\t\t\t\t\t\t\t\t\t'Rainfall+2h (mm)': 'float',\r\n\t\t\t\t\t\t\t\t\t'Average Wind Speed (kph)': 'float',\r\n\t\t\t\t\t\t\t\t\t})\r\n\r\n  validRecloses = create_total_rainfall_column(validRecloses, ['Rainfall-2h (mm)', \r\n      'Rainfall-1h (mm)',\r\n      'Rainfall+0h (mm)',\r\n      'Rainfall+1h (mm)',\r\n      ])\r\n\r\n  validRecloses['Average Rainfall'] = validRecloses[['Rainfall-2h (mm)', \r\n      'Rainfall-1h (mm)',\r\n      'Rainfall+0h (mm)',\r\n      'Rainfall+1h (mm)',\r\n      ]].mean(axis=1)\r\n  \r\n  return validRecloses\r\n\r\ndef get_weatherType(validRecloses):\r\n  \r\n  for idx, row in validRecloses.iterrows():\r\n    try:\r\n      total_rainfall = float(row['Total Rainfall Within 4h Window (mm)'])\r\n      avg_windspeed = float(row[\"Average Wind Speed (kph)\"])\r\n    except:\r\n      validRecloses.loc[idx, \"Weather type\"] = \"na\"\r\n\r\n    if total_rainfall == \"\" or avg_windspeed < 0:\r\n      validRecloses.loc[idx, \"Weather type\"] = \"na\"\r\n    elif (total_rainfall<0.2) and (avg_windspeed < 25):\r\n      validRecloses.loc[idx, \"Weather type\"] = 'Fine'\r\n    elif avg_windspeed >= 25 and total_rainfall >= 0.2:\r\n      validRecloses.loc[idx, \"Weather type\"] = 'Windy and Rainy'\r\n    elif avg_windspeed >= 25:\r\n      validRecloses.loc[idx, \"Weather type\"] = \"Windy\"\r\n    elif total_rainfall >= 0.2:\r\n      validRecloses.loc[idx, \"Weather type\"] = 'Rainy'\r\n     \r\n  return validRecloses\r\n    \r\n\r\n# you can add additional helper methods below.\r\ndef get_weatherJson(locationCode, datetime1):\r\n  # Get weather data\r\n  url = f'http://arcprd901/weather/?lt=aploc&lc={locationCode}&format=json&u=USER&k=KEY&histobs=1(date={str(datetime1.date())}, order=asc)'\r\n  response = requests.request(\"GET\", url, data={}, verify=False)\r\n  return xmltodict.parse(response.text)  # Parse xml to json\r\n\r\n# Takes a weather station and returns the current weather, or historical based on a given date.\r\n# Inputs:\r\n#         Station: string. Name of the weather station\r\n#         datetime: datetime. Returns weather data closest to this date.\r\ndef get_weatherData(station, datetime1=None):\r\n  # TODO: Check country code is AU, get where location name is = to station, otherwise error.\r\n\r\n  # Define Weather Debug Info\r\n  Weather_Debug_Info = \"\"\r\n\r\n  errorConditionsFormatted  = {\r\n    'obs_time_utc': \"na\",\r\n    'obs_time_local': \"na\",\r\n    'temp_c': \"na\",\r\n    'avg_wind_speed_kph': \"na\",\r\n    'rainfall_mm-2h': \"na\",\r\n    'rainfall_mm-1h': \"na\",\r\n    'rainfall_mm+0h': \"na\",\r\n    'rainfall_mm+1h': \"na\",\r\n    'rainfall_mm+2h': \"na\",\r\n    \"rainingDuring4hWindow\": \"na\",\r\n    'Weather_Debug_Info': Weather_Debug_Info,\r\n    }\r\n\r\n  try:\r\n    locationCode = df_stationToLocationCode[df_stationToLocationCode[\"name\"].str.lower()==station.lower()][\"customID\"].values[0]\r\n  except:\r\n    Weather_Debug_Info = f\"Station not found - The weather station for '{station}' could not be found in location code database\"\r\n\r\n    return errorConditionsFormatted\r\n\r\n  responseJson_onDay = get_weatherJson(locationCode, datetime1)\r\n  responseJson_DayAfter = get_weatherJson(locationCode, datetime1 + timedelta(days=1))\r\n  responseJson_DayBefore = get_weatherJson(locationCode, datetime1 + timedelta(days=-1))\r\n\r\n  # We need to get the historical weather data and find the nearest datapoint to when the reclose occurred.\r\n  observations_onDay = responseJson_onDay[\"data\"][\"weather\"][\"countries\"][\"country\"][\"location\"][\"historical_observations\"][\"historical_observation\"]\r\n  observations_dayAfter = responseJson_DayAfter[\"data\"][\"weather\"][\"countries\"][\"country\"][\"location\"][\"historical_observations\"][\"historical_observation\"]\r\n  observations_dayBefore = responseJson_DayBefore[\"data\"][\"weather\"][\"countries\"][\"country\"][\"location\"][\"historical_observations\"][\"historical_observation\"]\r\n\r\n  try:\r\n    # Get index of closest time\r\n    historicalTimes = [i['obs_time_local'][\"#text\"] for i in observations_onDay]\r\n    nearestIndex = get_IndexOfNearestTime(historicalTimes, datetime1)\r\n  except:\r\n    Weather_Debug_Info = \"No Weather Data - No data for day at weather station\"\r\n    return errorConditionsFormatted\r\n\r\n  # We require this logic to get 2 hours before/after incase the hours fall into the next or previous day.\r\n  # In this case we use a separately call from the API, since it only gives 1 day at a time. \r\n  try:\r\n\r\n    rainfall_mmAtTime = observations_onDay[nearestIndex]['rainfall_mm']['#text']\r\n\r\n    if datetime1.hour == 0:\r\n      rainfall_mm2hbefore = observations_dayBefore[23]['rainfall_mm']['#text']\r\n      rainfall_mm1hbefore = observations_dayBefore[22]['rainfall_mm']['#text']\r\n    elif datetime1.hour == 1:\r\n      rainfall_mm2hbefore = observations_dayBefore[23]['rainfall_mm']['#text']\r\n      rainfall_mm1hbefore = observations_onDay[nearestIndex-1]['rainfall_mm']['#text']\r\n    else:\r\n      rainfall_mm2hbefore = observations_onDay[nearestIndex-2]['rainfall_mm']['#text']\r\n      rainfall_mm1hbefore = observations_onDay[nearestIndex-1]['rainfall_mm']['#text']\r\n  \r\n    if datetime1.hour == 23:\r\n      rainfall_mm2hafter = observations_dayAfter[1]['rainfall_mm']['#text']\r\n      rainfall_mm1hafter = observations_dayAfter[0]['rainfall_mm']['#text']\r\n    elif datetime1.hour == 22:\r\n      rainfall_mm2hafter = observations_dayAfter[0]['rainfall_mm']['#text']\r\n      rainfall_mm1hafter = observations_onDay[nearestIndex+1]['rainfall_mm']['#text']\r\n    else:\r\n      rainfall_mm2hafter = observations_onDay[nearestIndex+2]['rainfall_mm']['#text']\r\n      rainfall_mm1hafter = observations_onDay[nearestIndex+1]['rainfall_mm']['#text']\r\n  except (IndexError, KeyError):\r\n      Weather_Debug_Info = \"No Weather Data - No data for day at weather station\"\r\n      return errorConditionsFormatted\r\n  # Try getting other weather variables\r\n  try:\r\n    temp_c = observations_onDay[nearestIndex]['temp_c']['#text']\r\n  except KeyError:\r\n    Weather_Debug_Info = \"Temperature unavailble.\"\r\n    return errorConditionsFormatted\r\n  try:\r\n    windSpeed = observations_onDay[nearestIndex]['avg_wind_speed_kph']['#text']\r\n  except KeyError:\r\n    windSpeed = observations_onDay[nearestIndex]['wind_speed_kph']['#text']\r\n    Weather_Debug_Info = Weather_Debug_Info + \"Average Wind Speed Unavailable. Windspeed at closest time to reclose used. \"\r\n  \r\n  rainWindow=[rainfall_mm2hbefore, rainfall_mm1hbefore, rainfall_mmAtTime, rainfall_mm1hafter, rainfall_mm2hafter]\r\n  rainingDuring4hWindow = rainingDuringWindow(rainWindow)\r\n\r\n  # Any errors in the weather data should be caught when setting the rain variables.\r\n  conditionsFormatted = {\r\n  'obs_time_utc': observations_onDay[nearestIndex]['obs_time_utc']['#text'],\r\n  'obs_time_local': observations_onDay[nearestIndex]['obs_time_local']['#text'],\r\n  'temp_c': temp_c,\r\n  'avg_wind_speed_kph': windSpeed,\r\n  'rainfall_mm-2h': rainfall_mm2hbefore,\r\n  'rainfall_mm-1h': rainfall_mm1hbefore,\r\n  'rainfall_mm+0h': rainfall_mmAtTime,\r\n  'rainfall_mm+1h': rainfall_mm1hafter,\r\n  'rainfall_mm+2h': rainfall_mm2hafter,\r\n  'rainingDuring4hWindow': rainingDuring4hWindow,\r\n  'Weather_Debug_Info': Weather_Debug_Info,\r\n  }\r\n\r\n  return conditionsFormatted\r\n\r\ndef rainingDuringWindow(rainWindow):\r\n  # The rainfall (mm) gets reset to 0mm at 9am daily.\r\n  # We check to see if it's been reset at all, and hasn't increased from 0mm\r\n  if rainWindow[3] == '0.0' and len(set(rainWindow)) == 2:\r\n    return \"No\"\r\n  \r\n  # In the second case we check to see if there has been rainfall since 9am, but it hasn't increased during the window\r\n  if len(set(rainWindow)) == 1:\r\n    return \"No\"\r\n  \r\n  # Rain must have occured\r\n  return \"Yes\"\r\n\r\n# Used for debugging offline\r\ndef set_yesterday(yesterdayIN):\r\n  global yesterday\r\n  yesterday = yesterdayIN\r\n  return\r\n\r\n# Given a list of datetimes and a pivot datetime, returns the index of the nearest datetime.\r\ndef get_IndexOfNearestTime(historicalTimes, datetime1):\r\n  from datetime import datetime\r\n  print(historicalTimes)\r\n  dates_list = [datetime.strptime(date1, '%Y-%m-%dT%H:%M:%S') for date1 in historicalTimes]\r\n  #dates_list = pd.to_datetime(historicalTimes)\r\n  nearestDate = nearest(dates_list, datetime1)\r\n  dateIndex = dates_list.index(nearestDate)\r\n  return dateIndex\r\n\r\n# Gets nearest date\r\ndef nearest(items, pivot):\r\n    return min(items, key=lambda x: abs(x - pivot))\r\n\r\n\r\ndef get_filterSustainedEvents(recloseData):\r\n  \"\"\"\r\n  get_filterSustainedEvents: Selects only momentary events & mark events that later sustain.\r\n                            \r\n  Parameters\r\n  ----------\r\n  recloseData : DataFrame\r\n      DF to transform\r\n  \r\n  Returns\r\n  ---------\r\n  recloseData : DataFrame\r\n      Copy of recloseData with sustained events removed and events with sustains on same device marked.\r\n  \"\"\"\r\n  recloseData = recloseData[recloseData[\"Textbox205\"].str.lower().isin([\"momentary\", \"sustained\"])]\r\n  pivot_table = pd.crosstab(index=recloseData[\"Textbox52\"], columns=recloseData[\"Textbox205\"])\r\n  pivot_table[\"Did Sustained Outage Occur\"] = ((pivot_table[\"Momentary\"]>0) & (pivot_table[\"Sustained\"]>0)).apply(lambda x: \"Yes\" if x else \"No\")\r\n  recloseData = recloseData.merge(pivot_table[[\"Did Sustained Outage Occur\"]], left_on=\"Textbox52\", right_index=True)\r\n  recloseData = recloseData[recloseData[\"Textbox205\"].str.lower().isin([\"momentary\"])] \r\n\r\n  return recloseData\r\n\r\ndef get_validRecloses(recloseData):\r\n  # Check if not prefix R or CB, remove from list\r\n  # If open, record in new temp DF\r\n  # If next is close & same as incident ID, and 2-10 seconds, add to df\r\n  # Append tempDF to actual df.\r\n\r\n\r\n  # Filter sustained events & mark those that had sustained events later.\r\n  recloseData = get_filterSustainedEvents(recloseData)\r\n\r\n  # Convert columns types\r\n  recloseData = recloseData[recloseData[\"DATE_TIME_OPERATED\"] != \"001-01-01 10:30:00\"]\r\n  recloseData[\"DEVICE_NAME\"] = recloseData[\"DEVICE_NAME\"].astype(str)\r\n  try:\r\n    recloseData['DATE_TIME_OPERATED'] =  pd.to_datetime(recloseData['DATE_TIME_OPERATED'], format='%Y-%m-%d %H:%M:%S')\r\n  except:\r\n    recloseData['DATE_TIME_OPERATED'] =  pd.to_datetime(recloseData['DATE_TIME_OPERATED'], format='%d/%m/%Y %H:%M:%S')\r\n\r\n  # -- Define variables --\r\n  outputDataframe = pd.DataFrame(columns={\r\n    \"Incident ID\": \"\",\r\n    \"Feeder ID\": \"\",\r\n    \"Feeder Name\": \"\",\r\n    \"Protection Device\": \"\",\r\n    \"Customers Impacted\": \"\",\r\n    \"Outage Start Time\": \"\",\r\n    \"Outage End Time\": \"\",\r\n    \"Seconds Open\": \"\",\r\n    \"Bushfire Risk Area\": \"\",\r\n    \"Closest Weather Station\": \"\",\r\n    \"Average Wind Speed (kph)\": \"\", \r\n    \"Rainfall-2h (mm)\": \"\", \r\n    \"Rainfall-1h (mm)\": \"\", \r\n    \"Rainfall+0h (mm)\": \"\", \r\n    \"Rainfall+1h (mm)\": \"\", \r\n    \"Rainfall+2h (mm)\": \"\", \r\n    \"Raining During 4h Window\": \"\",\r\n    \"Weather Debug Info\": \"\", \r\n    \"Did Sustained Outage Occur\": \"\", \r\n  })\r\n  tempRow = None\r\n\r\n  for idx, row in recloseData.iterrows():\r\n\r\n    if len(row[\"DEVICE_NAME\"])<3: # If less than 3 chars in device name, skip row\r\n      continue\r\n    elif row[\"DEVICE_NAME\"][:1]!=\"R\" and row[\"DEVICE_NAME\"][:2]!=\"CB\": # If device name doesn't start with \"R\" or \"CB\", skip row\r\n      continue\r\n\r\n    # If open command, save it and search for the close in next row. \r\n    # If found, we will add it to the outputDataframe.\r\n    if row[\"SwitchingCommand\"]==\"OPEN\":\r\n      tempRow = row\r\n      continue\r\n\r\n    # Check next close command\r\n    if row[\"SwitchingCommand\"]==\"CLOSE\":\r\n      # Check switching is from same incident\r\n      if tempRow[\"Textbox35\"]==row[\"Textbox35\"]: \r\n        # check the reclose time is between 2- 10 seconds (inclusive)\r\n        if 2 <= (row[\"DATE_TIME_OPERATED\"] - tempRow[\"DATE_TIME_OPERATED\"]).seconds <= 10:\r\n          if outputDataframe.empty == True: # Logic for the first row added\r\n            outputDataframe = format_reclosePair(tempRow, row).to_frame().T\r\n          else:\r\n            outputDataframe = outputDataframe.append(format_reclosePair(tempRow, row), ignore_index=True)\r\n          continue\r\n\r\n  if outputDataframe.empty:\r\n    return outputDataframe\r\n\r\n  # Add incident count and remove duplicate incidents\r\n  outputDataframe = countAndDropDuplicates(outputDataframe, \"Incident ID\", 'Incident Reclose Count')\r\n\r\n  return outputDataframe\r\n  \r\ndef countAndDropDuplicates(df, column, newCountColumnName):\r\n  df[newCountColumnName] = df.groupby(column)[column].transform('count')\r\n  df = df.drop_duplicates(subset=[column], keep=\"last\")\r\n  return df\r\n\r\ndef format_reclosePair(open, close):\r\n\r\n  # We are trying to find where the substation is given as \"LOCATION2\" instead of the feeder.  \r\n  # This happens on a 66kV line where it goes to a sub, not a feeder. It only occurs on CBs, which is why we check for the CB\r\n  # The guess here is that if it doesn't contain a hyphen with spaces either side, and isn't a CB, then it is showing the feeder.\r\n  if len(open[\"LOCATION2\"].split(\" - \")) == 1 and open[\"DEVICE_NAME\"][:2]==\"CB\": \r\n    \r\n    feederName = open[\"LOCATION2\"]\r\n\r\n    try:\r\n      feederID = df_substationToSSDMapping[df_substationToSSDMapping[\"Supply Source\"].str.lower()==open[\"LOCATION2\"].lower()][\"Supply Sub\"].values[0] # Use SSD instead of feederID, as requested by Julius\r\n    except:\r\n      try:\r\n        feederID = df_substationToSSDMapping[df_substationToSSDMapping[\"Feeder Name\"].str.lower().str.contains(open[\"LOCATION2\"].lower())==True][\"Feeder No\"].values[0]\r\n      except:\r\n        bushFireRisk = \"bushFireRiskForSubstationNotFound\"\r\n        feederID = feederName\r\n\r\n    bushFireRiskDF = df_bushFireRiskSubstations[df_bushFireRiskSubstations[\"SSD\"]==feederID][\"ABC indicator text\"]\r\n    if bushFireRiskDF.empty == True:\r\n      bushFireRisk = \"bushFireRiskForSubstationNotFound\"\r\n    else:\r\n      bushFireRisk = bushFireRiskDF.values[0]\r\n  else:\r\n    feederID = open[\"LOCATION2\"].split(\"-\")[0].strip()\r\n    try: \r\n      feederName = open[\"LOCATION2\"].split(\"-\")[1].strip()\r\n    except:\r\n      feederName = feederID\r\n\r\n    try:\r\n      # Check if bushfire risk is related to feeder. If not, it may be a substation still\r\n      bushFireRisk = df_bushFireRiskFeeders[df_bushFireRiskFeeders[\"Feeder\"]==feederID][\"BFRA\"].values[0]\r\n    except IndexError:\r\n      # Check substation list\r\n      bushFireRiskDF = df_bushFireRiskSubstations[df_bushFireRiskSubstations[\"SSD\"]==feederID][\"ABC indicator text\"]\r\n      if bushFireRiskDF.empty == True:\r\n        bushFireRisk = \"bushFireRiskForSubstationNotFound\"\r\n      else:\r\n        bushFireRisk = bushFireRiskDF.values[0]\r\n\r\n\r\n  weatherStation = get_weatherStation(open[\"LOCATION2\"])\r\n  weatherData = get_weatherData(weatherStation, datetime1 = open[\"DATE_TIME_OPERATED\"])\r\n\r\n  formattedDict = {\r\n    \"Incident ID\": open[\"Textbox35\"],\r\n    \"Feeder ID\": feederID,\r\n    \"Feeder Name\": feederName,\r\n    \"Protection Device\": open[\"Textbox52\"],\r\n    \"Customers Impacted\": open[\"NAME6\"],\r\n    \"Outage Start Time\": open[\"DATE_TIME_OPERATED\"],\r\n    \"Outage End Time\": close[\"DATE_TIME_OPERATED\"],\r\n    \"Seconds Open\": (close[\"DATE_TIME_OPERATED\"] - open[\"DATE_TIME_OPERATED\"]).seconds,\r\n    \"Bushfire Risk Area\": bushFireRisk,\r\n    \"Closest Weather Station\": weatherStation,\r\n    \"Average Wind Speed (kph)\": weatherData[\"avg_wind_speed_kph\"], \r\n    \"Rainfall-2h (mm)\": weatherData[\"rainfall_mm-2h\"], \r\n    \"Rainfall-1h (mm)\": weatherData[\"rainfall_mm-1h\"], \r\n    \"Rainfall+0h (mm)\": weatherData[\"rainfall_mm+0h\"], \r\n    \"Rainfall+1h (mm)\": weatherData[\"rainfall_mm+1h\"], \r\n    \"Rainfall+2h (mm)\": weatherData[\"rainfall_mm+2h\"], \r\n    \"Raining During 4h Window\": weatherData[\"rainingDuring4hWindow\"],\r\n    \"Weather Debug Info\": weatherData[\"Weather_Debug_Info\"],\r\n    \"Did Sustained Outage Occur\": open[\"Did Sustained Outage Occur\"]\r\n    \r\n  }\r\n\r\n  return pd.Series(formattedDict)\r\n\r\ndef get_weatherStation(feederName):\r\n  idx = df_feederToWeatherStationMapping[df_feederToWeatherStationMapping[\"FeederName\"] == feederName].index\r\n  if idx.empty == True:\r\n    idx = df_feederToWeatherStationMapping[df_feederToWeatherStationMapping[\"FeederName\"].str.contains(feederName)].index\r\n  if idx.empty == True:\r\n    idx = df_feederToWeatherStationMapping[df_feederToWeatherStationMapping[\"SubstationName\"].str.contains(feederName)].index\r\n  if idx.empty == True:\r\n    print(f\"\\nNo Weather Station found for {feederName}\")\r\n    return \"weatherStationNotFound\"\r\n  return df_feederToWeatherStationMapping.loc[idx, \"WeatherStation\"].values[0]"
  results:
    - SUCCESS
